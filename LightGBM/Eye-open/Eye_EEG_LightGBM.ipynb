{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>eye</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>P7</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>P8</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4329.23</td>\n",
       "      <td>4009.23</td>\n",
       "      <td>Open</td>\n",
       "      <td>4289.23</td>\n",
       "      <td>4148.21</td>\n",
       "      <td>4350.26</td>\n",
       "      <td>4586.15</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4641.03</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4238.46</td>\n",
       "      <td>4211.28</td>\n",
       "      <td>4280.51</td>\n",
       "      <td>4635.90</td>\n",
       "      <td>4393.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4324.62</td>\n",
       "      <td>4004.62</td>\n",
       "      <td>Open</td>\n",
       "      <td>4293.85</td>\n",
       "      <td>4148.72</td>\n",
       "      <td>4342.05</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4638.97</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4226.67</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4279.49</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4384.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4327.69</td>\n",
       "      <td>4006.67</td>\n",
       "      <td>Open</td>\n",
       "      <td>4295.38</td>\n",
       "      <td>4156.41</td>\n",
       "      <td>4336.92</td>\n",
       "      <td>4583.59</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4630.26</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4206.67</td>\n",
       "      <td>4282.05</td>\n",
       "      <td>4628.72</td>\n",
       "      <td>4389.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4328.72</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>Open</td>\n",
       "      <td>4296.41</td>\n",
       "      <td>4155.90</td>\n",
       "      <td>4343.59</td>\n",
       "      <td>4582.56</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4630.77</td>\n",
       "      <td>4217.44</td>\n",
       "      <td>4235.38</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4287.69</td>\n",
       "      <td>4632.31</td>\n",
       "      <td>4396.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4326.15</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>Open</td>\n",
       "      <td>4292.31</td>\n",
       "      <td>4151.28</td>\n",
       "      <td>4347.69</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4095.90</td>\n",
       "      <td>4627.69</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4244.10</td>\n",
       "      <td>4212.82</td>\n",
       "      <td>4288.21</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4398.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AF3       F7   eye       F3      FC5       T7       P7       O1  \\\n",
       "0  4329.23  4009.23  Open  4289.23  4148.21  4350.26  4586.15  4096.92   \n",
       "1  4324.62  4004.62  Open  4293.85  4148.72  4342.05  4586.67  4097.44   \n",
       "2  4327.69  4006.67  Open  4295.38  4156.41  4336.92  4583.59  4096.92   \n",
       "3  4328.72  4011.79  Open  4296.41  4155.90  4343.59  4582.56  4097.44   \n",
       "4  4326.15  4011.79  Open  4292.31  4151.28  4347.69  4586.67  4095.90   \n",
       "\n",
       "        O2       P8       T8      FC6       F4       F8      AF4  \n",
       "0  4641.03  4222.05  4238.46  4211.28  4280.51  4635.90  4393.85  \n",
       "1  4638.97  4210.77  4226.67  4207.69  4279.49  4632.82  4384.10  \n",
       "2  4630.26  4207.69  4222.05  4206.67  4282.05  4628.72  4389.23  \n",
       "3  4630.77  4217.44  4235.38  4210.77  4287.69  4632.31  4396.41  \n",
       "4  4627.69  4210.77  4244.10  4212.82  4288.21  4632.82  4398.46  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and preview data\n",
    "df = pd.read_csv(\"eeg_clean.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14980 entries, 0 to 14979\n",
      "Data columns (total 15 columns):\n",
      "AF3    14980 non-null float64\n",
      "F7     14980 non-null float64\n",
      "eye    14980 non-null object\n",
      "F3     14980 non-null float64\n",
      "FC5    14980 non-null float64\n",
      "T7     14980 non-null float64\n",
      "P7     14980 non-null float64\n",
      "O1     14980 non-null float64\n",
      "O2     14980 non-null float64\n",
      "P8     14980 non-null float64\n",
      "T8     14980 non-null float64\n",
      "FC6    14980 non-null float64\n",
      "F4     14980 non-null float64\n",
      "F8     14980 non-null float64\n",
      "AF4    14980 non-null float64\n",
      "dtypes: float64(14), object(1)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# view summary of dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open      8257\n",
       "Closed    6723\n",
       "Name: eye, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print positive/negative labels\n",
    "df['eye'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#labelencoder = LabelEncoder()\n",
    "#df['eye'] = labelencoder.fit_transform(df['eye'])\n",
    "\n",
    "df.loc[df['eye'] == 'Closed', 'eye'] = 0\n",
    "df.loc[df['eye'] == 'Open', 'eye'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['eye'], axis = 1)\n",
    "y = df['eye']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>P7</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>P8</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4329.23</td>\n",
       "      <td>4009.23</td>\n",
       "      <td>4289.23</td>\n",
       "      <td>4148.21</td>\n",
       "      <td>4350.26</td>\n",
       "      <td>4586.15</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4641.03</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4238.46</td>\n",
       "      <td>4211.28</td>\n",
       "      <td>4280.51</td>\n",
       "      <td>4635.90</td>\n",
       "      <td>4393.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4324.62</td>\n",
       "      <td>4004.62</td>\n",
       "      <td>4293.85</td>\n",
       "      <td>4148.72</td>\n",
       "      <td>4342.05</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4638.97</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4226.67</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4279.49</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4384.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4327.69</td>\n",
       "      <td>4006.67</td>\n",
       "      <td>4295.38</td>\n",
       "      <td>4156.41</td>\n",
       "      <td>4336.92</td>\n",
       "      <td>4583.59</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4630.26</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4206.67</td>\n",
       "      <td>4282.05</td>\n",
       "      <td>4628.72</td>\n",
       "      <td>4389.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4328.72</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>4296.41</td>\n",
       "      <td>4155.90</td>\n",
       "      <td>4343.59</td>\n",
       "      <td>4582.56</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4630.77</td>\n",
       "      <td>4217.44</td>\n",
       "      <td>4235.38</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4287.69</td>\n",
       "      <td>4632.31</td>\n",
       "      <td>4396.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4326.15</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>4292.31</td>\n",
       "      <td>4151.28</td>\n",
       "      <td>4347.69</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4095.90</td>\n",
       "      <td>4627.69</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4244.10</td>\n",
       "      <td>4212.82</td>\n",
       "      <td>4288.21</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4398.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14975</th>\n",
       "      <td>4281.03</td>\n",
       "      <td>3990.26</td>\n",
       "      <td>4245.64</td>\n",
       "      <td>4116.92</td>\n",
       "      <td>4333.85</td>\n",
       "      <td>4614.36</td>\n",
       "      <td>4074.87</td>\n",
       "      <td>4625.64</td>\n",
       "      <td>4203.08</td>\n",
       "      <td>4221.54</td>\n",
       "      <td>4171.28</td>\n",
       "      <td>4269.23</td>\n",
       "      <td>4593.33</td>\n",
       "      <td>4340.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14976</th>\n",
       "      <td>4276.92</td>\n",
       "      <td>3991.79</td>\n",
       "      <td>4245.13</td>\n",
       "      <td>4110.77</td>\n",
       "      <td>4332.82</td>\n",
       "      <td>4615.38</td>\n",
       "      <td>4073.33</td>\n",
       "      <td>4621.54</td>\n",
       "      <td>4194.36</td>\n",
       "      <td>4217.44</td>\n",
       "      <td>4162.56</td>\n",
       "      <td>4259.49</td>\n",
       "      <td>4590.26</td>\n",
       "      <td>4333.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14977</th>\n",
       "      <td>4277.44</td>\n",
       "      <td>3990.77</td>\n",
       "      <td>4246.67</td>\n",
       "      <td>4113.85</td>\n",
       "      <td>4333.33</td>\n",
       "      <td>4615.38</td>\n",
       "      <td>4072.82</td>\n",
       "      <td>4623.59</td>\n",
       "      <td>4193.33</td>\n",
       "      <td>4212.82</td>\n",
       "      <td>4160.51</td>\n",
       "      <td>4257.95</td>\n",
       "      <td>4591.79</td>\n",
       "      <td>4339.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14978</th>\n",
       "      <td>4284.62</td>\n",
       "      <td>3991.79</td>\n",
       "      <td>4251.28</td>\n",
       "      <td>4122.05</td>\n",
       "      <td>4334.36</td>\n",
       "      <td>4616.41</td>\n",
       "      <td>4080.51</td>\n",
       "      <td>4628.72</td>\n",
       "      <td>4200.00</td>\n",
       "      <td>4220.00</td>\n",
       "      <td>4165.64</td>\n",
       "      <td>4267.18</td>\n",
       "      <td>4596.41</td>\n",
       "      <td>4350.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14979</th>\n",
       "      <td>4287.69</td>\n",
       "      <td>3997.44</td>\n",
       "      <td>4260.00</td>\n",
       "      <td>4121.03</td>\n",
       "      <td>4333.33</td>\n",
       "      <td>4616.41</td>\n",
       "      <td>4088.72</td>\n",
       "      <td>4638.46</td>\n",
       "      <td>4212.31</td>\n",
       "      <td>4226.67</td>\n",
       "      <td>4167.69</td>\n",
       "      <td>4274.36</td>\n",
       "      <td>4597.95</td>\n",
       "      <td>4350.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14980 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AF3       F7       F3      FC5       T7       P7       O1       O2  \\\n",
       "0      4329.23  4009.23  4289.23  4148.21  4350.26  4586.15  4096.92  4641.03   \n",
       "1      4324.62  4004.62  4293.85  4148.72  4342.05  4586.67  4097.44  4638.97   \n",
       "2      4327.69  4006.67  4295.38  4156.41  4336.92  4583.59  4096.92  4630.26   \n",
       "3      4328.72  4011.79  4296.41  4155.90  4343.59  4582.56  4097.44  4630.77   \n",
       "4      4326.15  4011.79  4292.31  4151.28  4347.69  4586.67  4095.90  4627.69   \n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "14975  4281.03  3990.26  4245.64  4116.92  4333.85  4614.36  4074.87  4625.64   \n",
       "14976  4276.92  3991.79  4245.13  4110.77  4332.82  4615.38  4073.33  4621.54   \n",
       "14977  4277.44  3990.77  4246.67  4113.85  4333.33  4615.38  4072.82  4623.59   \n",
       "14978  4284.62  3991.79  4251.28  4122.05  4334.36  4616.41  4080.51  4628.72   \n",
       "14979  4287.69  3997.44  4260.00  4121.03  4333.33  4616.41  4088.72  4638.46   \n",
       "\n",
       "            P8       T8      FC6       F4       F8      AF4  \n",
       "0      4222.05  4238.46  4211.28  4280.51  4635.90  4393.85  \n",
       "1      4210.77  4226.67  4207.69  4279.49  4632.82  4384.10  \n",
       "2      4207.69  4222.05  4206.67  4282.05  4628.72  4389.23  \n",
       "3      4217.44  4235.38  4210.77  4287.69  4632.31  4396.41  \n",
       "4      4210.77  4244.10  4212.82  4288.21  4632.82  4398.46  \n",
       "...        ...      ...      ...      ...      ...      ...  \n",
       "14975  4203.08  4221.54  4171.28  4269.23  4593.33  4340.51  \n",
       "14976  4194.36  4217.44  4162.56  4259.49  4590.26  4333.33  \n",
       "14977  4193.33  4212.82  4160.51  4257.95  4591.79  4339.49  \n",
       "14978  4200.00  4220.00  4165.64  4267.18  4596.41  4350.77  \n",
       "14979  4212.31  4226.67  4167.69  4274.36  4597.95  4350.77  \n",
       "\n",
       "[14980 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>P7</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>P8</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4329.23</td>\n",
       "      <td>4009.23</td>\n",
       "      <td>4289.23</td>\n",
       "      <td>4148.21</td>\n",
       "      <td>4350.26</td>\n",
       "      <td>4586.15</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4641.03</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4238.46</td>\n",
       "      <td>4211.28</td>\n",
       "      <td>4280.51</td>\n",
       "      <td>4635.90</td>\n",
       "      <td>4393.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4324.62</td>\n",
       "      <td>4004.62</td>\n",
       "      <td>4293.85</td>\n",
       "      <td>4148.72</td>\n",
       "      <td>4342.05</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4638.97</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4226.67</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4279.49</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4384.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4327.69</td>\n",
       "      <td>4006.67</td>\n",
       "      <td>4295.38</td>\n",
       "      <td>4156.41</td>\n",
       "      <td>4336.92</td>\n",
       "      <td>4583.59</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4630.26</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4206.67</td>\n",
       "      <td>4282.05</td>\n",
       "      <td>4628.72</td>\n",
       "      <td>4389.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4328.72</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>4296.41</td>\n",
       "      <td>4155.90</td>\n",
       "      <td>4343.59</td>\n",
       "      <td>4582.56</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4630.77</td>\n",
       "      <td>4217.44</td>\n",
       "      <td>4235.38</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4287.69</td>\n",
       "      <td>4632.31</td>\n",
       "      <td>4396.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4326.15</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>4292.31</td>\n",
       "      <td>4151.28</td>\n",
       "      <td>4347.69</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4095.90</td>\n",
       "      <td>4627.69</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4244.10</td>\n",
       "      <td>4212.82</td>\n",
       "      <td>4288.21</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4398.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AF3       F7       F3      FC5       T7       P7       O1       O2  \\\n",
       "0  4329.23  4009.23  4289.23  4148.21  4350.26  4586.15  4096.92  4641.03   \n",
       "1  4324.62  4004.62  4293.85  4148.72  4342.05  4586.67  4097.44  4638.97   \n",
       "2  4327.69  4006.67  4295.38  4156.41  4336.92  4583.59  4096.92  4630.26   \n",
       "3  4328.72  4011.79  4296.41  4155.90  4343.59  4582.56  4097.44  4630.77   \n",
       "4  4326.15  4011.79  4292.31  4151.28  4347.69  4586.67  4095.90  4627.69   \n",
       "\n",
       "        P8       T8      FC6       F4       F8      AF4  \n",
       "0  4222.05  4238.46  4211.28  4280.51  4635.90  4393.85  \n",
       "1  4210.77  4226.67  4207.69  4279.49  4632.82  4384.10  \n",
       "2  4207.69  4222.05  4206.67  4282.05  4628.72  4389.23  \n",
       "3  4217.44  4235.38  4210.77  4287.69  4632.31  4396.41  \n",
       "4  4210.77  4244.10  4212.82  4288.21  4632.82  4398.46  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: eye, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier()\n",
    "lgb_params = {\n",
    "    'boosting_type': ['gbdt'],\n",
    "    'objective': ['binary'],\n",
    "    'num_leaves': [99],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [10],\n",
    "    'lambda_l1': [0, 0.3],\n",
    "    'lambda_l2':[0, 0.3],\n",
    "    'feature_fraction': [0.6, 0.8], \n",
    "    'bagging_fraction': [0.6, 0.8], \n",
    "    'bagging_freq':[1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.911, total=   0.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.916, total=   0.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.912, total=   0.2s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.909, total=   0.2s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.912, total=   0.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.918, total=   0.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    1.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.918, total=   0.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    1.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.912, total=   0.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    2.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.912, total=   0.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    2.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.913, total=   0.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.911, total=   0.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.914, total=   0.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.920, total=   0.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.915, total=   0.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.923, total=   0.2s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.920, total=   0.2s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.914, total=   0.2s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.919, total=   0.2s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.920, total=   0.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.919, total=   0.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.924, total=   0.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.919, total=   0.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.919, total=   0.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.921, total=   0.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.921, total=   0.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.917, total=   0.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.921, total=   0.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.915, total=   0.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.914, total=   0.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.921, total=   0.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.919, total=   0.5s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.913, total=   0.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.922, total=   0.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.919, total=   0.4s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.908, total=   0.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.6, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.922, total=   0.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.920, total=   0.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.918, total=   0.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.921, total=   0.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.922, total=   0.4s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.920, total=   0.5s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.920, total=   0.5s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.923, total=   0.5s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.918, total=   0.5s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.922, total=   0.4s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.924, total=   0.4s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.918, total=   0.4s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=1, boosting_type=gbdt, feature_fraction=0.8, lambda_l1=0.3, lambda_l2=0.3, learning_rate=0.1, max_depth=10, num_leaves=99, objective=binary, score=0.922, total=   0.4s\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:   15.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                      colsample_bytree=1.0,\n",
       "                                      importance_type='split',\n",
       "                                      learning_rate=0.1, max_depth=-1,\n",
       "                                      min_child_samples=20,\n",
       "                                      min_child_weight=0.001,\n",
       "                                      min_split_gain=0.0, n_estimators=100,\n",
       "                                      n_jobs=-1, num_leaves=31, objective=None,\n",
       "                                      random_state=None, reg_alpha=0.0,\n",
       "                                      reg_lambda=0.0, silent=Tru...\n",
       "                                      subsample_freq=0),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'bagging_fraction': [0.6, 0.8], 'bagging_freq': [1],\n",
       "                         'boosting_type': ['gbdt'],\n",
       "                         'feature_fraction': [0.6, 0.8], 'lambda_l1': [0, 0.3],\n",
       "                         'lambda_l2': [0, 0.3], 'learning_rate': [0.1],\n",
       "                         'max_depth': [10], 'num_leaves': [99],\n",
       "                         'objective': ['binary']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv = GridSearchCV(model, lgb_params, cv = 3, verbose = 10)\n",
    "grid_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_fraction': 0.8, 'bagging_freq': 1, 'boosting_type': 'gbdt', 'feature_fraction': 0.8, 'lambda_l1': 0.3, 'lambda_l2': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'num_leaves': 99, 'objective': 'binary'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5836, number of negative: 4650\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3490\n",
      "[LightGBM] [Info] Number of data points in the train set: 10486, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.556552 -> initscore=0.227178\n",
      "[LightGBM] [Info] Start training from score 0.227178\n",
      "[1]\tvalid_0's binary_logloss: 0.651055\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.616885\n",
      "[3]\tvalid_0's binary_logloss: 0.587336\n",
      "[4]\tvalid_0's binary_logloss: 0.564844\n",
      "[5]\tvalid_0's binary_logloss: 0.541094\n",
      "[6]\tvalid_0's binary_logloss: 0.521095\n",
      "[7]\tvalid_0's binary_logloss: 0.505611\n",
      "[8]\tvalid_0's binary_logloss: 0.4904\n",
      "[9]\tvalid_0's binary_logloss: 0.474501\n",
      "[10]\tvalid_0's binary_logloss: 0.459541\n",
      "[11]\tvalid_0's binary_logloss: 0.44782\n",
      "[12]\tvalid_0's binary_logloss: 0.435437\n",
      "[13]\tvalid_0's binary_logloss: 0.424875\n",
      "[14]\tvalid_0's binary_logloss: 0.414271\n",
      "[15]\tvalid_0's binary_logloss: 0.404023\n",
      "[16]\tvalid_0's binary_logloss: 0.394609\n",
      "[17]\tvalid_0's binary_logloss: 0.386475\n",
      "[18]\tvalid_0's binary_logloss: 0.378859\n",
      "[19]\tvalid_0's binary_logloss: 0.370918\n",
      "[20]\tvalid_0's binary_logloss: 0.364524\n",
      "[21]\tvalid_0's binary_logloss: 0.358643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's binary_logloss: 0.353084\n",
      "[23]\tvalid_0's binary_logloss: 0.348166\n",
      "[24]\tvalid_0's binary_logloss: 0.341824\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's binary_logloss: 0.336713\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's binary_logloss: 0.332089\n",
      "[27]\tvalid_0's binary_logloss: 0.327643\n",
      "[28]\tvalid_0's binary_logloss: 0.322645\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's binary_logloss: 0.319448\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's binary_logloss: 0.316576\n",
      "[31]\tvalid_0's binary_logloss: 0.312379\n",
      "[32]\tvalid_0's binary_logloss: 0.30767\n",
      "[33]\tvalid_0's binary_logloss: 0.303449\n",
      "[34]\tvalid_0's binary_logloss: 0.299509\n",
      "[35]\tvalid_0's binary_logloss: 0.295291\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's binary_logloss: 0.292322\n",
      "[37]\tvalid_0's binary_logloss: 0.289002\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's binary_logloss: 0.286944\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's binary_logloss: 0.285384\n",
      "[40]\tvalid_0's binary_logloss: 0.283039\n",
      "[41]\tvalid_0's binary_logloss: 0.280642\n",
      "[42]\tvalid_0's binary_logloss: 0.277586\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's binary_logloss: 0.275217\n",
      "[44]\tvalid_0's binary_logloss: 0.272177\n",
      "[45]\tvalid_0's binary_logloss: 0.269587\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's binary_logloss: 0.267945\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's binary_logloss: 0.266371\n",
      "[48]\tvalid_0's binary_logloss: 0.263904\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's binary_logloss: 0.2621\n",
      "[50]\tvalid_0's binary_logloss: 0.258653\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's binary_logloss: 0.25689\n",
      "[52]\tvalid_0's binary_logloss: 0.254153\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[53]\tvalid_0's binary_logloss: 0.252334\n",
      "[54]\tvalid_0's binary_logloss: 0.250321\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[55]\tvalid_0's binary_logloss: 0.24986\n",
      "[56]\tvalid_0's binary_logloss: 0.247359\n",
      "[57]\tvalid_0's binary_logloss: 0.24524\n",
      "[58]\tvalid_0's binary_logloss: 0.242884\n",
      "[59]\tvalid_0's binary_logloss: 0.240675\n",
      "[60]\tvalid_0's binary_logloss: 0.23822\n",
      "[61]\tvalid_0's binary_logloss: 0.236435\n",
      "[62]\tvalid_0's binary_logloss: 0.234698\n",
      "[63]\tvalid_0's binary_logloss: 0.233044\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[64]\tvalid_0's binary_logloss: 0.232221\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[65]\tvalid_0's binary_logloss: 0.23076\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[66]\tvalid_0's binary_logloss: 0.229018\n",
      "[67]\tvalid_0's binary_logloss: 0.227428\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[68]\tvalid_0's binary_logloss: 0.225387\n",
      "[69]\tvalid_0's binary_logloss: 0.223998\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\tvalid_0's binary_logloss: 0.222682\n",
      "[71]\tvalid_0's binary_logloss: 0.220838\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[72]\tvalid_0's binary_logloss: 0.219753\n",
      "[73]\tvalid_0's binary_logloss: 0.217943\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[74]\tvalid_0's binary_logloss: 0.217101\n",
      "[75]\tvalid_0's binary_logloss: 0.215476\n",
      "[76]\tvalid_0's binary_logloss: 0.213333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[77]\tvalid_0's binary_logloss: 0.212456\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[78]\tvalid_0's binary_logloss: 0.211205\n",
      "[79]\tvalid_0's binary_logloss: 0.209752\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\tvalid_0's binary_logloss: 0.209259\n",
      "[81]\tvalid_0's binary_logloss: 0.207637\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[82]\tvalid_0's binary_logloss: 0.206473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[83]\tvalid_0's binary_logloss: 0.205555\n",
      "[84]\tvalid_0's binary_logloss: 0.20436\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[85]\tvalid_0's binary_logloss: 0.203402\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[86]\tvalid_0's binary_logloss: 0.203001\n",
      "[87]\tvalid_0's binary_logloss: 0.201956\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[88]\tvalid_0's binary_logloss: 0.20113\n",
      "[89]\tvalid_0's binary_logloss: 0.200588\n",
      "[90]\tvalid_0's binary_logloss: 0.199243\n",
      "[91]\tvalid_0's binary_logloss: 0.197829\n",
      "[92]\tvalid_0's binary_logloss: 0.196795\n",
      "[93]\tvalid_0's binary_logloss: 0.19584\n",
      "[94]\tvalid_0's binary_logloss: 0.194541\n",
      "[95]\tvalid_0's binary_logloss: 0.193979\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[96]\tvalid_0's binary_logloss: 0.19308\n",
      "[97]\tvalid_0's binary_logloss: 0.192029\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[98]\tvalid_0's binary_logloss: 0.191743\n",
      "[99]\tvalid_0's binary_logloss: 0.190858\n",
      "[100]\tvalid_0's binary_logloss: 0.18963\n",
      "[101]\tvalid_0's binary_logloss: 0.188535\n",
      "[102]\tvalid_0's binary_logloss: 0.187899\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[103]\tvalid_0's binary_logloss: 0.187366\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[104]\tvalid_0's binary_logloss: 0.18682\n",
      "[105]\tvalid_0's binary_logloss: 0.185769\n",
      "[106]\tvalid_0's binary_logloss: 0.184822\n",
      "[107]\tvalid_0's binary_logloss: 0.184026\n",
      "[108]\tvalid_0's binary_logloss: 0.182921\n",
      "[109]\tvalid_0's binary_logloss: 0.181925\n",
      "[110]\tvalid_0's binary_logloss: 0.180861\n",
      "[111]\tvalid_0's binary_logloss: 0.179858\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[112]\tvalid_0's binary_logloss: 0.179368\n",
      "[113]\tvalid_0's binary_logloss: 0.178761\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[114]\tvalid_0's binary_logloss: 0.178646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[115]\tvalid_0's binary_logloss: 0.178343\n",
      "[116]\tvalid_0's binary_logloss: 0.177439\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[117]\tvalid_0's binary_logloss: 0.177133\n",
      "[118]\tvalid_0's binary_logloss: 0.176457\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[119]\tvalid_0's binary_logloss: 0.175748\n",
      "[120]\tvalid_0's binary_logloss: 0.175176\n",
      "[121]\tvalid_0's binary_logloss: 0.174665\n",
      "[122]\tvalid_0's binary_logloss: 0.174158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123]\tvalid_0's binary_logloss: 0.173455\n",
      "[124]\tvalid_0's binary_logloss: 0.172829\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[125]\tvalid_0's binary_logloss: 0.172422\n",
      "[126]\tvalid_0's binary_logloss: 0.171837\n",
      "[127]\tvalid_0's binary_logloss: 0.171128\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[128]\tvalid_0's binary_logloss: 0.170612\n",
      "[129]\tvalid_0's binary_logloss: 0.170391\n",
      "[130]\tvalid_0's binary_logloss: 0.170015\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[131]\tvalid_0's binary_logloss: 0.16935\n",
      "[132]\tvalid_0's binary_logloss: 0.168509\n",
      "[133]\tvalid_0's binary_logloss: 0.167609\n",
      "[134]\tvalid_0's binary_logloss: 0.166974\n",
      "[135]\tvalid_0's binary_logloss: 0.166234\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[136]\tvalid_0's binary_logloss: 0.166095\n",
      "[137]\tvalid_0's binary_logloss: 0.16514\n",
      "[138]\tvalid_0's binary_logloss: 0.164551\n",
      "[139]\tvalid_0's binary_logloss: 0.16403\n",
      "[140]\tvalid_0's binary_logloss: 0.163568\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[141]\tvalid_0's binary_logloss: 0.163153\n",
      "[142]\tvalid_0's binary_logloss: 0.162717\n",
      "[143]\tvalid_0's binary_logloss: 0.162298\n",
      "[144]\tvalid_0's binary_logloss: 0.1616\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[145]\tvalid_0's binary_logloss: 0.161158\n",
      "[146]\tvalid_0's binary_logloss: 0.16055\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[147]\tvalid_0's binary_logloss: 0.16037\n",
      "[148]\tvalid_0's binary_logloss: 0.160118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[149]\tvalid_0's binary_logloss: 0.15987\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[150]\tvalid_0's binary_logloss: 0.159686\n",
      "[151]\tvalid_0's binary_logloss: 0.1595\n",
      "[152]\tvalid_0's binary_logloss: 0.159051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[153]\tvalid_0's binary_logloss: 0.158797\n",
      "[154]\tvalid_0's binary_logloss: 0.15809\n",
      "[155]\tvalid_0's binary_logloss: 0.157282\n",
      "[156]\tvalid_0's binary_logloss: 0.156573\n",
      "[157]\tvalid_0's binary_logloss: 0.155975\n",
      "[158]\tvalid_0's binary_logloss: 0.155601\n",
      "[159]\tvalid_0's binary_logloss: 0.155212\n",
      "[160]\tvalid_0's binary_logloss: 0.154551\n",
      "[161]\tvalid_0's binary_logloss: 0.154215\n",
      "[162]\tvalid_0's binary_logloss: 0.153735\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[163]\tvalid_0's binary_logloss: 0.153643\n",
      "[164]\tvalid_0's binary_logloss: 0.153072\n",
      "[165]\tvalid_0's binary_logloss: 0.152655\n",
      "[166]\tvalid_0's binary_logloss: 0.151999\n",
      "[167]\tvalid_0's binary_logloss: 0.151491\n",
      "[168]\tvalid_0's binary_logloss: 0.150755\n",
      "[169]\tvalid_0's binary_logloss: 0.150212\n",
      "[170]\tvalid_0's binary_logloss: 0.149683\n",
      "[171]\tvalid_0's binary_logloss: 0.149085\n",
      "[172]\tvalid_0's binary_logloss: 0.148681\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[173]\tvalid_0's binary_logloss: 0.148466\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[174]\tvalid_0's binary_logloss: 0.148339\n",
      "[175]\tvalid_0's binary_logloss: 0.148121\n",
      "[176]\tvalid_0's binary_logloss: 0.147918\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[177]\tvalid_0's binary_logloss: 0.147465\n",
      "[178]\tvalid_0's binary_logloss: 0.14701\n",
      "[179]\tvalid_0's binary_logloss: 0.146799\n",
      "[180]\tvalid_0's binary_logloss: 0.146547\n",
      "[181]\tvalid_0's binary_logloss: 0.146406\n",
      "[182]\tvalid_0's binary_logloss: 0.145999\n",
      "[183]\tvalid_0's binary_logloss: 0.145625\n",
      "[184]\tvalid_0's binary_logloss: 0.145364\n",
      "[185]\tvalid_0's binary_logloss: 0.145067\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[186]\tvalid_0's binary_logloss: 0.145012\n",
      "[187]\tvalid_0's binary_logloss: 0.144785\n",
      "[188]\tvalid_0's binary_logloss: 0.1446\n",
      "[189]\tvalid_0's binary_logloss: 0.14429\n",
      "[190]\tvalid_0's binary_logloss: 0.143996\n",
      "[191]\tvalid_0's binary_logloss: 0.14395\n",
      "[192]\tvalid_0's binary_logloss: 0.143535\n",
      "[193]\tvalid_0's binary_logloss: 0.143375\n",
      "[194]\tvalid_0's binary_logloss: 0.142976\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[195]\tvalid_0's binary_logloss: 0.142698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[196]\tvalid_0's binary_logloss: 0.142414\n",
      "[197]\tvalid_0's binary_logloss: 0.142344\n",
      "[198]\tvalid_0's binary_logloss: 0.142186\n",
      "[199]\tvalid_0's binary_logloss: 0.141918\n",
      "[200]\tvalid_0's binary_logloss: 0.141712\n",
      "[201]\tvalid_0's binary_logloss: 0.141596\n",
      "[202]\tvalid_0's binary_logloss: 0.141187\n",
      "[203]\tvalid_0's binary_logloss: 0.140975\n",
      "[204]\tvalid_0's binary_logloss: 0.140904\n",
      "[205]\tvalid_0's binary_logloss: 0.140755\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[206]\tvalid_0's binary_logloss: 0.140579\n",
      "[207]\tvalid_0's binary_logloss: 0.140686\n",
      "[208]\tvalid_0's binary_logloss: 0.140309\n",
      "[209]\tvalid_0's binary_logloss: 0.140039\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[210]\tvalid_0's binary_logloss: 0.140026\n",
      "[211]\tvalid_0's binary_logloss: 0.139587\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[212]\tvalid_0's binary_logloss: 0.139536\n",
      "[213]\tvalid_0's binary_logloss: 0.139244\n",
      "[214]\tvalid_0's binary_logloss: 0.139047\n",
      "[215]\tvalid_0's binary_logloss: 0.138698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[216]\tvalid_0's binary_logloss: 0.138551\n",
      "[217]\tvalid_0's binary_logloss: 0.138424\n",
      "[218]\tvalid_0's binary_logloss: 0.138215\n",
      "[219]\tvalid_0's binary_logloss: 0.137905\n",
      "[220]\tvalid_0's binary_logloss: 0.137596\n",
      "[221]\tvalid_0's binary_logloss: 0.137276\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[222]\tvalid_0's binary_logloss: 0.137118\n",
      "[223]\tvalid_0's binary_logloss: 0.137093\n",
      "[224]\tvalid_0's binary_logloss: 0.137078\n",
      "[225]\tvalid_0's binary_logloss: 0.137143\n",
      "[226]\tvalid_0's binary_logloss: 0.13699\n",
      "[227]\tvalid_0's binary_logloss: 0.137058\n",
      "[228]\tvalid_0's binary_logloss: 0.137123\n",
      "[229]\tvalid_0's binary_logloss: 0.136962\n",
      "[230]\tvalid_0's binary_logloss: 0.136884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[231]\tvalid_0's binary_logloss: 0.13681\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[232]\tvalid_0's binary_logloss: 0.136658\n",
      "[233]\tvalid_0's binary_logloss: 0.136624\n",
      "[234]\tvalid_0's binary_logloss: 0.136613\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[235]\tvalid_0's binary_logloss: 0.136619\n",
      "[236]\tvalid_0's binary_logloss: 0.136339\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[237]\tvalid_0's binary_logloss: 0.136323\n",
      "[238]\tvalid_0's binary_logloss: 0.136313\n",
      "[239]\tvalid_0's binary_logloss: 0.136237\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[240]\tvalid_0's binary_logloss: 0.136138\n",
      "[241]\tvalid_0's binary_logloss: 0.135866\n",
      "[242]\tvalid_0's binary_logloss: 0.135895\n",
      "[243]\tvalid_0's binary_logloss: 0.135726\n",
      "[244]\tvalid_0's binary_logloss: 0.135478\n",
      "[245]\tvalid_0's binary_logloss: 0.135257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[246]\tvalid_0's binary_logloss: 0.135237\n",
      "[247]\tvalid_0's binary_logloss: 0.135092\n",
      "[248]\tvalid_0's binary_logloss: 0.134951\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[249]\tvalid_0's binary_logloss: 0.134886\n",
      "[250]\tvalid_0's binary_logloss: 0.134745\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[251]\tvalid_0's binary_logloss: 0.13449\n",
      "[252]\tvalid_0's binary_logloss: 0.134355\n",
      "[253]\tvalid_0's binary_logloss: 0.13436\n",
      "[254]\tvalid_0's binary_logloss: 0.134104\n",
      "[255]\tvalid_0's binary_logloss: 0.133928\n",
      "[256]\tvalid_0's binary_logloss: 0.133766\n",
      "[257]\tvalid_0's binary_logloss: 0.133781\n",
      "[258]\tvalid_0's binary_logloss: 0.133684\n",
      "[259]\tvalid_0's binary_logloss: 0.133506\n",
      "[260]\tvalid_0's binary_logloss: 0.133491\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[261]\tvalid_0's binary_logloss: 0.133424\n",
      "[262]\tvalid_0's binary_logloss: 0.133391\n",
      "[263]\tvalid_0's binary_logloss: 0.133252\n",
      "[264]\tvalid_0's binary_logloss: 0.133291\n",
      "[265]\tvalid_0's binary_logloss: 0.13319\n",
      "[266]\tvalid_0's binary_logloss: 0.133146\n",
      "[267]\tvalid_0's binary_logloss: 0.132971\n",
      "[268]\tvalid_0's binary_logloss: 0.132863\n",
      "[269]\tvalid_0's binary_logloss: 0.132747\n",
      "[270]\tvalid_0's binary_logloss: 0.132604\n",
      "[271]\tvalid_0's binary_logloss: 0.132487\n",
      "[272]\tvalid_0's binary_logloss: 0.132527\n",
      "[273]\tvalid_0's binary_logloss: 0.132181\n",
      "[274]\tvalid_0's binary_logloss: 0.13198\n",
      "[275]\tvalid_0's binary_logloss: 0.131873\n",
      "[276]\tvalid_0's binary_logloss: 0.131717\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[277]\tvalid_0's binary_logloss: 0.131944\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[278]\tvalid_0's binary_logloss: 0.131835\n",
      "[279]\tvalid_0's binary_logloss: 0.131707\n",
      "[280]\tvalid_0's binary_logloss: 0.13154\n",
      "[281]\tvalid_0's binary_logloss: 0.131334\n",
      "[282]\tvalid_0's binary_logloss: 0.131359\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[283]\tvalid_0's binary_logloss: 0.13123\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[284]\tvalid_0's binary_logloss: 0.131002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[285]\tvalid_0's binary_logloss: 0.130735\n",
      "[286]\tvalid_0's binary_logloss: 0.130834\n",
      "[287]\tvalid_0's binary_logloss: 0.130654\n",
      "[288]\tvalid_0's binary_logloss: 0.130559\n",
      "[289]\tvalid_0's binary_logloss: 0.130312\n",
      "[290]\tvalid_0's binary_logloss: 0.130304\n",
      "[291]\tvalid_0's binary_logloss: 0.130334\n",
      "[292]\tvalid_0's binary_logloss: 0.130306\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[293]\tvalid_0's binary_logloss: 0.130248\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[294]\tvalid_0's binary_logloss: 0.13023\n",
      "[295]\tvalid_0's binary_logloss: 0.130255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[296]\tvalid_0's binary_logloss: 0.130173\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[297]\tvalid_0's binary_logloss: 0.130072\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[298]\tvalid_0's binary_logloss: 0.130014\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[299]\tvalid_0's binary_logloss: 0.129941\n",
      "[300]\tvalid_0's binary_logloss: 0.129944\n",
      "[301]\tvalid_0's binary_logloss: 0.129922\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[302]\tvalid_0's binary_logloss: 0.129792\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[303]\tvalid_0's binary_logloss: 0.129697\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[304]\tvalid_0's binary_logloss: 0.129779\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[305]\tvalid_0's binary_logloss: 0.129698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[306]\tvalid_0's binary_logloss: 0.129534\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[307]\tvalid_0's binary_logloss: 0.129481\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[308]\tvalid_0's binary_logloss: 0.12941\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[309]\tvalid_0's binary_logloss: 0.129386\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[310]\tvalid_0's binary_logloss: 0.12942\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[311]\tvalid_0's binary_logloss: 0.129437\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[312]\tvalid_0's binary_logloss: 0.129331\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[313]\tvalid_0's binary_logloss: 0.129324\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[314]\tvalid_0's binary_logloss: 0.129178\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[315]\tvalid_0's binary_logloss: 0.129014\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[316]\tvalid_0's binary_logloss: 0.128869\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[317]\tvalid_0's binary_logloss: 0.1288\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[318]\tvalid_0's binary_logloss: 0.12867\n",
      "[319]\tvalid_0's binary_logloss: 0.12865\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[320]\tvalid_0's binary_logloss: 0.128611\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[321]\tvalid_0's binary_logloss: 0.128552\n",
      "[322]\tvalid_0's binary_logloss: 0.128647\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[323]\tvalid_0's binary_logloss: 0.128502\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[324]\tvalid_0's binary_logloss: 0.128343\n",
      "[325]\tvalid_0's binary_logloss: 0.128241\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[326]\tvalid_0's binary_logloss: 0.128077\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[327]\tvalid_0's binary_logloss: 0.127933\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[328]\tvalid_0's binary_logloss: 0.127912\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[329]\tvalid_0's binary_logloss: 0.127908\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[330]\tvalid_0's binary_logloss: 0.12785\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[331]\tvalid_0's binary_logloss: 0.127733\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[332]\tvalid_0's binary_logloss: 0.127694\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[333]\tvalid_0's binary_logloss: 0.127609\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[334]\tvalid_0's binary_logloss: 0.127667\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[335]\tvalid_0's binary_logloss: 0.127682\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[336]\tvalid_0's binary_logloss: 0.127596\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[337]\tvalid_0's binary_logloss: 0.127673\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[338]\tvalid_0's binary_logloss: 0.127592\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[339]\tvalid_0's binary_logloss: 0.127455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[340]\tvalid_0's binary_logloss: 0.127394\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[341]\tvalid_0's binary_logloss: 0.127498\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[342]\tvalid_0's binary_logloss: 0.127474\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[343]\tvalid_0's binary_logloss: 0.127372\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[344]\tvalid_0's binary_logloss: 0.12743\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[345]\tvalid_0's binary_logloss: 0.127359\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[346]\tvalid_0's binary_logloss: 0.127269\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[347]\tvalid_0's binary_logloss: 0.127152\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[348]\tvalid_0's binary_logloss: 0.127074\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[349]\tvalid_0's binary_logloss: 0.12718\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[350]\tvalid_0's binary_logloss: 0.127166\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[351]\tvalid_0's binary_logloss: 0.127179\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[352]\tvalid_0's binary_logloss: 0.127188\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[353]\tvalid_0's binary_logloss: 0.127114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[354]\tvalid_0's binary_logloss: 0.127102\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[355]\tvalid_0's binary_logloss: 0.127004\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[356]\tvalid_0's binary_logloss: 0.12691\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[357]\tvalid_0's binary_logloss: 0.126978\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[358]\tvalid_0's binary_logloss: 0.126928\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[359]\tvalid_0's binary_logloss: 0.126877\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[360]\tvalid_0's binary_logloss: 0.12695\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[361]\tvalid_0's binary_logloss: 0.127012\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[362]\tvalid_0's binary_logloss: 0.126956\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[363]\tvalid_0's binary_logloss: 0.126901\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[364]\tvalid_0's binary_logloss: 0.126848\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[365]\tvalid_0's binary_logloss: 0.126884\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[366]\tvalid_0's binary_logloss: 0.126912\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[367]\tvalid_0's binary_logloss: 0.126844\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[368]\tvalid_0's binary_logloss: 0.126778\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[369]\tvalid_0's binary_logloss: 0.126667\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[370]\tvalid_0's binary_logloss: 0.126634\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[371]\tvalid_0's binary_logloss: 0.126581\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[372]\tvalid_0's binary_logloss: 0.126663\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[373]\tvalid_0's binary_logloss: 0.126616\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[374]\tvalid_0's binary_logloss: 0.126474\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[375]\tvalid_0's binary_logloss: 0.126406\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[376]\tvalid_0's binary_logloss: 0.126325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[377]\tvalid_0's binary_logloss: 0.126296\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[378]\tvalid_0's binary_logloss: 0.12626\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[379]\tvalid_0's binary_logloss: 0.126332\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[380]\tvalid_0's binary_logloss: 0.126225\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[381]\tvalid_0's binary_logloss: 0.126204\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[382]\tvalid_0's binary_logloss: 0.126209\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[383]\tvalid_0's binary_logloss: 0.126172\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[384]\tvalid_0's binary_logloss: 0.126229\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[385]\tvalid_0's binary_logloss: 0.126256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[386]\tvalid_0's binary_logloss: 0.126187\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[387]\tvalid_0's binary_logloss: 0.126042\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[388]\tvalid_0's binary_logloss: 0.126015\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[389]\tvalid_0's binary_logloss: 0.125947\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[390]\tvalid_0's binary_logloss: 0.125985\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[391]\tvalid_0's binary_logloss: 0.125943\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[392]\tvalid_0's binary_logloss: 0.1259\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[393]\tvalid_0's binary_logloss: 0.125892\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[394]\tvalid_0's binary_logloss: 0.125821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[395]\tvalid_0's binary_logloss: 0.125756\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[396]\tvalid_0's binary_logloss: 0.125671\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[397]\tvalid_0's binary_logloss: 0.125602\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[398]\tvalid_0's binary_logloss: 0.125496\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[399]\tvalid_0's binary_logloss: 0.125518\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\tvalid_0's binary_logloss: 0.125586\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[401]\tvalid_0's binary_logloss: 0.125474\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[402]\tvalid_0's binary_logloss: 0.125519\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[403]\tvalid_0's binary_logloss: 0.125564\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[404]\tvalid_0's binary_logloss: 0.125549\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[405]\tvalid_0's binary_logloss: 0.125489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[406]\tvalid_0's binary_logloss: 0.125392\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[407]\tvalid_0's binary_logloss: 0.125353\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[408]\tvalid_0's binary_logloss: 0.125234\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[409]\tvalid_0's binary_logloss: 0.125181\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[410]\tvalid_0's binary_logloss: 0.125169\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[411]\tvalid_0's binary_logloss: 0.125175\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[412]\tvalid_0's binary_logloss: 0.125158\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[413]\tvalid_0's binary_logloss: 0.125181\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[414]\tvalid_0's binary_logloss: 0.125297\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[415]\tvalid_0's binary_logloss: 0.125354\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[416]\tvalid_0's binary_logloss: 0.125431\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[417]\tvalid_0's binary_logloss: 0.125349\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[418]\tvalid_0's binary_logloss: 0.12536\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[419]\tvalid_0's binary_logloss: 0.12542\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[420]\tvalid_0's binary_logloss: 0.125417\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[421]\tvalid_0's binary_logloss: 0.125445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[422]\tvalid_0's binary_logloss: 0.125413\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[423]\tvalid_0's binary_logloss: 0.125424\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[424]\tvalid_0's binary_logloss: 0.125469\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[425]\tvalid_0's binary_logloss: 0.12544\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[426]\tvalid_0's binary_logloss: 0.125489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[427]\tvalid_0's binary_logloss: 0.125489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[428]\tvalid_0's binary_logloss: 0.125363\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[429]\tvalid_0's binary_logloss: 0.125417\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[430]\tvalid_0's binary_logloss: 0.125372\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[431]\tvalid_0's binary_logloss: 0.125511\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[432]\tvalid_0's binary_logloss: 0.125459\n",
      "Early stopping, best iteration is:\n",
      "[412]\tvalid_0's binary_logloss: 0.125158\n"
     ]
    }
   ],
   "source": [
    "# define categorical variables\n",
    "# build the lightgbm model\n",
    "import lightgbm as lgb\n",
    "best_params = grid_cv.best_params_\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_test = lgb.Dataset(X_test, y_test)\n",
    "bst = lgb.train(best_params, lgb_train, 1000, valid_sets=lgb_test, early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 864x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "lgb.plot_importance(bst, max_num_features=30)\n",
    "plt.title(\"Feature importances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bst.predict(X_test)\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "y_pred_train = bst.predict(X_train)\n",
    "y_pred_train = np.where(y_pred_train > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.0000\n",
      "Test set score: 0.9544\n"
     ]
    }
   ],
   "source": [
    "# view accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "# print the scores on training and test set\n",
    "print('Training set score: {:.4f}'.format(accuracy_score(y_train, y_pred_train)))\n",
    "print('Test set score: {:.4f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = bst.predict(X_test)\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, probs)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.3f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([-0.03, 1])\n",
    "plt.ylim([0, 1.03])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.72736400000001,
   "position": {
    "height": "40px",
    "left": "1475.45px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
